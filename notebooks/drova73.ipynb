{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c57d7d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neiro/anaconda3/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ba583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b358465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24c84fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=[0.485, 0.456, 0.406] # это среднее и стандартное отклонение всего датасета (обычно imagenet), на котором обучали большую сеть\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "         transforms.Resize(1024),\n",
    "         #transforms.RandomRotation(30),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.CenterCrop(1024),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=mean,\n",
    "                              std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddcf3f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = ''\n",
    "datasetFolderName=root_path+'data'\n",
    "sourceFiles=[]\n",
    "classLabels=['0', '1', '3']\n",
    "X=[]\n",
    "Y=[]\n",
    "\n",
    "train_path=datasetFolderName+'/train/'\n",
    "validation_path=datasetFolderName+'/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "503603e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transferBetweenFolders(source, dest, splitRate): \n",
    "    global sourceFiles\n",
    "    sourceFiles=os.listdir(source)\n",
    "    if(len(sourceFiles)!=0):\n",
    "        transferFileNumbers=int(len(sourceFiles)*splitRate)\n",
    "        transferIndex=random.sample(range(0, len(sourceFiles)), transferFileNumbers)\n",
    "        for eachIndex in transferIndex:\n",
    "            shutil.move(source+str(sourceFiles[eachIndex]), dest+str(sourceFiles[eachIndex]))\n",
    "    else:\n",
    "        print(\"No file moved. Source empty!\")\n",
    "        \n",
    "def transferAllClassBetweenFolders(source, dest, splitRate):\n",
    "    for label in classLabels:\n",
    "        transferBetweenFolders(datasetFolderName+'/'+source+'/'+label+'/', \n",
    "                               datasetFolderName+'/'+dest+'/'+label+'/', \n",
    "                               splitRate)\n",
    "\n",
    "def my_metrics(y_true, y_pred):\n",
    "    accuracy=accuracy_score(y_true, y_pred)\n",
    "    precision=precision_score(y_true, y_pred,average='weighted')\n",
    "    f1Score=f1_score(y_true, y_pred, average='weighted') \n",
    "    print(\"Accuracy  : {}\".format(accuracy))\n",
    "    print(\"Precision : {}\".format(precision))\n",
    "    print(\"f1Score : {}\".format(f1Score))\n",
    "    cm=confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    return accuracy, precision, f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1511d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareNameWithLabels(folderName):\n",
    "    sourceFiles=os.listdir(datasetFolderName+'/train/'+folderName)\n",
    "    for val in sourceFiles:\n",
    "        X.append(val)\n",
    "        for i in range(len(classLabels)):\n",
    "            if(folderName==classLabels[i]):\n",
    "                Y.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "220930ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize file names and class labels in X and Y variables\n",
    "for i in range(len(classLabels)):\n",
    "    prepareNameWithLabels(classLabels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7076af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X)\n",
    "Y=np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a7a5617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd65a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, loss_fn, optimizer, train_loader,val_loader, n_epoch=10):\n",
    "    best_metrics = 0\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        print(f'Epoch {epoch + 1}')\n",
    "        train_dataiter = iter(train_loader)\n",
    "        for i, batch in enumerate(tqdm(train_dataiter)):\n",
    "            X_batch, y_batch = batch\n",
    "\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = net(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            metrics = []\n",
    "            for batch in val_loader:\n",
    "                x, y = batch\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                y_pred = net(x)\n",
    "\n",
    "                y_true = y.detach().cpu().numpy() \n",
    "                y_pred = np.argmax(y_pred.detach().cpu().numpy(), axis=1)\n",
    "                f1_batch = f1_score(y_true, y_pred, average='macro')\n",
    "                metrics.append(f1_batch)\n",
    "            \n",
    "            metrics = np.mean(np.array(metrics))\n",
    "            # если стало лучше - сохраняем на диск и обновляем лучшую метрику\n",
    "            if metrics > best_metrics: \n",
    "                print('New best model with test f1 macro:', metrics)\n",
    "                torch.save(net.state_dict(), './best_model.pt')\n",
    "                best_metrics = metrics\n",
    "            if metrics == 1.0:\n",
    "                break\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69771e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "152fb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "vgg16.classifier = nn.Sequential(*list(vgg16.classifier.children()))[:-1]\n",
    "\n",
    "class New_VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vgg16 = vgg16\n",
    "        # for param in self.vgg16.features.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        self.fc = nn.Sequential(nn.Linear(4096, 100),\n",
    "                                nn.Linear(100, 3))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.vgg16(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "net = New_VGG16().to(device)\n",
    "\n",
    "lr = 5e-4\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75edb1f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fold 1\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:43<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model with test f1 macro: 0.8396624472573837\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:43<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model with test f1 macro: 0.8860759493670886\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:44<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:44<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:44<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model with test f1 macro: 0.9324894514767931\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:44<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model with test f1 macro: 0.9915611814345993\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:44<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:44<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:44<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:44<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:44<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:44<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:44<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:44<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:43<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:42<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model with test f1 macro: 1.0\n",
      "Results for fold 2\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:40<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model with test f1 macro: 0.9746835443037974\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:40<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model with test f1 macro: 1.0\n",
      "Results for fold 3\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:40<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model with test f1 macro: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ===============Stratified K-Fold======================\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "skf.get_n_splits(X, Y)\n",
    "foldNum=0\n",
    "for train_index, val_index in skf.split(X, Y):\n",
    "    #First cut all images from validation to train (if any exists)\n",
    "    transferAllClassBetweenFolders('validation', 'train', 1.0)\n",
    "    foldNum+=1\n",
    "    print(\"Results for fold\",foldNum)\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "    # Move validation images of this fold from train folder to the validation folder\n",
    "    for eachIndex in range(len(X_val)):\n",
    "        classLabel=''\n",
    "        for i in range(len(classLabels)):\n",
    "            if(Y_val[eachIndex]==i):\n",
    "                classLabel=classLabels[i]\n",
    "        #Then, copy the validation images to the validation folder\n",
    "        shutil.move(datasetFolderName+'/train/'+classLabel+'/'+X_val[eachIndex], \n",
    "                    datasetFolderName+'/validation/'+classLabel+'/'+X_val[eachIndex])\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(datasetFolderName+'/train/', transform=transform_train)\n",
    "    val_dataset = datasets.ImageFolder(datasetFolderName+'/validation/', transform=transform_train)\n",
    "    \n",
    "    batch_size = 2\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2)\n",
    "    \n",
    "    image_datasets = {'train': train_dataset, 'val': val_dataset}\n",
    "    dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    class_names = ['0','1','3']\n",
    "    \n",
    "    net = train(net, loss_fn, optimizer, train_loader, val_loader, n_epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d5e2674",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata_path = 'datatest'\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "         transforms.Resize(1024),\n",
    "         transforms.CenterCrop(1024),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406], # это среднее и стандартное отклонение всего датасета (обычно imagenet), на котором обучали большую сеть\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_data = datasets.ImageFolder(testdata_path, transform=transform_test)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=2)\n",
    "\n",
    "\n",
    "pred = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = net(x)\n",
    "\n",
    "        y_pred = np.argmax(y_pred.detach().cpu().numpy(), axis=1).tolist()\n",
    "        pred.extend(y_pred)\n",
    "    \n",
    "pred2 = [3 if x==2 else x for x in pred]\n",
    "\n",
    "import pandas as pd\n",
    "sample = pd.read_csv(\"sample.csv\")\n",
    "sample['class'] = pred2\n",
    "\n",
    "import os\n",
    "files = []\n",
    " \n",
    "for filename in os.listdir('datatest/testset'):\n",
    "        if filename[filename.rfind(\".\") + 1:] in ['jpg', 'jpeg', 'png']:\n",
    "            files.append(filename.split(\".\")[0])\n",
    "files.sort()\n",
    "\n",
    "sample['id'] = files\n",
    "sample['id'] = sample['id'].astype(int)\n",
    "sample = sample.sort_values(by=['id'])\n",
    "sample.to_csv('sample73.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
